{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17c28eb4",
   "metadata": {},
   "source": [
    "# PYNQ‑Z2 Lab Protocol: YUV Filter with Streams + DMA\n",
    "\n",
    "**Audience:** Embedded Systems students\n",
    "**Board:** PYNQ‑Z2 (Zynq‑7020)\n",
    "**Tools:** Vitis HLS, Vivado, PYNQ (Jupyter)\n",
    "**Goal:** Implement a streaming RGB→YUV→filter→RGB accelerator, integrate it with AXI DMA, and measure speedup vs. a Python baseline.\n",
    "\n",
    "---\n",
    "\n",
    "## Why filter in YUV?\n",
    "\n",
    "* **Perceptual separation:** YUV splits luminance (**Y**) from chrominance (**U, V**). Many visual tasks—brightness/contrast tweaks, denoising, edge enhancement—primarily affect **Y** without shifting color.\n",
    "* **Cleaner color handling:** Adjusting **Y** avoids RGB cross‑talk; color fidelity holds while brightness changes. You can also filter **U/V** (e.g., chroma noise reduction) independently.\n",
    "* **Bandwidth & compression awareness:** Video systems commonly operate in YUV (e.g., 4:2:0). Thinking in YUV maps to real pipelines students will meet in the wild.\n",
    "\n",
    "> In this lab we scale the **Y** channel, then convert back to RGB—simple, visible, and stream‑friendly.\n",
    "\n",
    "## Why `hls::stream`?\n",
    "\n",
    "* **Throughput via pipelining:** Streams let stages run concurrently (source → `rgb2yuv` → `scale_y` → `yuv2rgb` → sink). With `#pragma HLS DATAFLOW`, HLS schedules them as a pipeline.\n",
    "* **Backpressure built‑in:** AXI‑Stream handshakes (`TVALID/TREADY`) ensure no drops under bursty traffic.\n",
    "* **Small buffers:** Process pixels as they arrive; avoid full‑frame BRAMs.\n",
    "* **AXI‑Stream ready:** Streams map naturally to AXIS for DMA/video subsystems.\n",
    "\n",
    "## Why a DMA engine?\n",
    "\n",
    "* **Fast PS↔PL transfers:** AXI DMA moves large buffers between DDR and your accelerator without CPU copies.\n",
    "* **MM2S/S2MM:** Memory‑to‑Stream feeds pixels into the IP; Stream‑to‑Memory collects the results.\n",
    "* **Scales with image size:** Sustained throughput with minimal CPU involvement; clean timing measurements.\n",
    "\n",
    "---\n",
    "\n",
    "## Provided HLS top (summary)\n",
    "\n",
    "The top function uses AXI‑Stream I/O and a float parameter `scale_Y`:\n",
    "\n",
    "```c\n",
    "#pragma HLS INTERFACE axis      port=stream_in\n",
    "#pragma HLS INTERFACE axis      port=stream_out\n",
    "// Expose scale_Y via AXI‑Lite (verify/add if missing):\n",
    "#pragma HLS INTERFACE s_axilite port=scale_Y bundle=CTRL\n",
    "#pragma HLS INTERFACE s_axilite port=return  bundle=CTRL\n",
    "// Optional to enable stage concurrency:\n",
    "#pragma HLS DATAFLOW\n",
    "```\n",
    "\n",
    "> The internal stages: `rgb2yuv` → `scale_y` → `yuv2rgb` pass `ap_axis<24,...>` frames and preserve `TLAST`.\n",
    "\n",
    "---\n",
    "\n",
    "## Part A — Software baseline (Python on PYNQ)\n",
    "\n",
    "1. Copy `yuv_filter_soft.ipynb` and a test image (e.g., `input.png`) to the board’s Jupyter folder.\n",
    "2. Run the notebook:\n",
    "3. Record the **time per frame**; this is your CPU baseline.\n",
    "\n",
    "---\n",
    "\n",
    "## Part B — Build HLS IP in Vitis HLS\n",
    "\n",
    "1. **Create HLS Component** (C/C++), name `yuv_filter_hls`. Set **Clock** to **100 MHz** to match FCLK0.\n",
    "2. **Add source**: your provided `yuv_filter.cpp` (with the pragmas above).\n",
    "   Ensure top function is named `yuv_filter` and ports are AXIS + AXI‑Lite (for `scale_Y`).\n",
    "3. **Testbench**: Use the provided `yuv_filter_tb.cpp` to test functionality.\n",
    "4. **C Simulation** → verify functional behavior.\n",
    "5. **C Synthesis** → check latency/II; expect II≈1 per pixel after DATAFLOW.\n",
    "6. **(Optional) C/RTL Co‑Sim** → confirm stream protocol passes.\n",
    "7. **Export RTL** → *Package IP*. Note the **IP repository path**.\n",
    "\n",
    "---\n",
    "\n",
    "## Part C — Vivado Block Design (PS + DMA + HLS IP)\n",
    "\n",
    "1. **New Project** targeting **PYNQ‑Z2** (board).\n",
    "2. **Create Block Design** (`system`).\n",
    "3. **Add IP:** `ZYNQ7 Processing System` → **Run Block Automation** (DDR, clocks, MIO).\n",
    "4. **Add IP:** `AXI Direct Memory Access` and configure it by double-click on it (enable **MM2S** and **S2MM** channels; disable SG for simplicity).\n",
    "   Also add **AXI SmartConnect/Interconnect** as prompted by automation.\n",
    "5. **Add your HLS IP** from the repo (*Settings → IP → Repository → Add*).\n",
    "6. **Hook up control (AXI‑Lite):**\n",
    "\n",
    "   * Connect **DMA** control and **yuv_filter** control to **PS M_AXI_GP0** (Connection Automation helps).\n",
    "   * Assign addresses in **Address Editor**.\n",
    "7. **Hook up memory (HP port):**\n",
    "\n",
    "   * Enable **S_AXI_HP0** on the Zynq PS.\n",
    "   * Connect **DMA MM2S/S2MM** master ports to **S_AXI_HP0** via SmartConnect.\n",
    "8. **Hook up streams:**\n",
    "\n",
    "   * **MM2S M_AXIS** → **yuv_filter s_axis**.\n",
    "   * **yuv_filter m_axis** → **S2MM S_AXIS**.\n",
    "9. **Data width check:**\n",
    "\n",
    "   * The HLS IP streams **32‑bit** pixels. If the DMA’s AXIS width isn’t 32, change it.\n",
    "10. **Clocks/Resets:** Drive IP, DMA, and converters from **FCLK_CLK0 (100 MHz)** and a **Processor System Reset**.\n",
    "11. **Validate Design** (green check) → fix any DRCs.\n",
    "12. **Generate HDL Wrapper** (let Vivado manage it).\n",
    "13. **Run** Synthesis → Implementation → **Generate Bitstream**.\n",
    "14. Find artifacts:\n",
    "\n",
    "    * Bitstream: `.../impl_1/system_wrapper.bit`\n",
    "    * Handoff (.hwh): in the BD `system` folder (search for `*.hwh`).\n",
    "\n",
    "> **Overlay naming:** Rename to shared base (e.g., `yuv.bit`, `yuv.hwh`).\n",
    "\n",
    "---\n",
    "\n",
    "## Part D — Run on PYNQ with DMA\n",
    "\n",
    "1. Copy to the board: `yuv.bit`, `yuv.hwh`, `yuv_filter_hard.ipynb`, and a test image.\n",
    "2. Run the notebook:\n",
    "3. Compare to the CPU result (timing and a quick visual diff). For a number, compute MSE:\n",
    "\n",
    "```python\n",
    "from yuv_filter_numpy import yuv_filter_numpy\n",
    "cpu = yuv_filter_numpy(np.array(Image.open('input.png').convert('RGB')), 1.15)\n",
    "import numpy as np\n",
    "mse = np.mean((cpu.astype(np.int16) - out_rgb.astype(np.int16))**2)\n",
    "print('MSE vs CPU:', mse)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Deliverables\n",
    "\n",
    "* **Diagram/Screenshot** of the Vivado Block Design (PS, DMA, DataWidthConv if used, HLS IP).\n",
    "* **Timing table** (CPU vs. HW) for at least two `scale_Y` values and two image sizes.\n",
    "* **Result images** (CPU and HW) for one case.\n",
    "* **Notes**: stream width choice, TKEEP/TLAST handling, clocking, any issues + fixes.\n",
    "\n",
    "---\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "* **Can’t see IP in Vivado:** Add the correct repo folder (contains `component.xml`) and *Refresh*.\n",
    "* **DMA errors / hangs:** Ensure both DMA control ports are mapped, clocks connected, and `recv.transfer()` is called **before** `send.transfer()`; wait on both.\n",
    "* **No `.hwh` found:** It’s generated alongside the block design; search the project tree for `*.hwh`.\n",
    "* **Color looks off:** Remember the RGB↔YUV math uses limited‑range offsets (16/128). Check for extra scaling or incorrect channel order.\n",
    "* **Throughput low:** Enable `#pragma HLS DATAFLOW` and ensure each stage reads/writes the stream once per pixel (II≈1). Keep PL at 100 MHz initially.\n",
    "\n",
    "---\n",
    "\n",
    "## Optional extensions\n",
    "\n",
    "* Filter **U/V** channels (e.g., chroma denoise) and compare artifacts.\n",
    "* Swap to **VDMA** and operate on video frames/lines with `TLAST` per line.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
